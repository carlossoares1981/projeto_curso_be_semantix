{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Otimizar todos os dados do hdfs para uma tabela Hive particionada por município."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "-rw-r--r--   3 root supergroup   62492959 2021-07-10 01:28 /user/carlos/projeto/HIST_PAINEL_COVIDBR_2020_Parte1_06jul2021.csv\r\n",
      "-rw-r--r--   3 root supergroup   76520681 2021-07-10 01:28 /user/carlos/projeto/HIST_PAINEL_COVIDBR_2020_Parte2_06jul2021.csv\r\n",
      "-rw-r--r--   3 root supergroup   91120916 2021-07-10 01:28 /user/carlos/projeto/HIST_PAINEL_COVIDBR_2021_Parte1_06jul2021.csv\r\n",
      "-rw-r--r--   3 root supergroup    3046774 2021-07-10 01:28 /user/carlos/projeto/HIST_PAINEL_COVIDBR_2021_Parte2_06jul2021.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/carlos/projeto/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "_schema =[\n",
    "    StructField(\"regiao\", StringType()), \n",
    "    StructField(\"estado\", StringType()),\n",
    "    StructField(\"municipio\", StringType()), \n",
    "    StructField(\"coduf\", IntegerType()),\n",
    "    StructField(\"codmun\", IntegerType()), \n",
    "    StructField(\"codRegiaoSaude\", IntegerType()), \n",
    "    StructField(\"nomeRegiaoSaude\", StringType()), \n",
    "    StructField(\"data\", DateType()), \n",
    "    StructField(\"semanaEpi\", IntegerType()),\n",
    "    StructField(\"populacaoTCU2019\", IntegerType()), \n",
    "    StructField(\"casosAcumulado\", IntegerType()), \n",
    "    StructField(\"casosNovos\", IntegerType()), \n",
    "    StructField(\"obitosAcumulado\", IntegerType()), \n",
    "    StructField(\"obitosNovos\", IntegerType()), \n",
    "    StructField(\"Recuperadosnovos\", IntegerType()), \n",
    "    StructField(\"emAcompanhamentoNovos\", IntegerType()), \n",
    "    StructField(\"nterior_metropolitana\", IntegerType())\n",
    "    \n",
    "]\n",
    "\n",
    "str_type = StructType(_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos  = spark.read.csv('/user/carlos/projeto/*.csv', schema=str_type, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquivos.write.parquet().partitionBy(\"codmun\").mode(\"overwrite\").saveAsTable(\"/user/carlos/hist_covid\")\n",
    "arquivos.write.parquet(\"/user/carlos/hist_covid\",partitionBy='codmun', compression='snappy',mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Criar as 3 vizualizações pelo Spark com os dados enviados para o HDFS:\n",
    "\n",
    "# Visualização 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "painel = spark.read.parquet(\"/user/carlos/hist_covid\")\n",
    "painel.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------------+\n",
      "|Recuperadosnovos|emAcompanhamentoNovos|\n",
      "+----------------+---------------------+\n",
      "|        17262646|              1065477|\n",
      "+----------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_data = painel.agg(max('data').alias('max_data'))\n",
    "painel1 = painel.join(max_data, painel.data == max_data.max_data, 'inner').filter(painel.regiao == \"Brasil\").select(\"Recuperadosnovos\",\"emAcompanhamentoNovos\")\n",
    "painel1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "painel2 = painel.join(max_data, painel.data == max_data.max_data, 'inner')\\\n",
    ".filter(painel.regiao == \"Brasil\")\\\n",
    ".withColumn('Incidentes', round((col(\"casosAcumulado\")  / col(\"populacaoTCU2019\"))*100000.00,2))\n",
    "\n",
    "painel2_vf = painel2.select(\"casosAcumulado\", \"casosNovos\", \"Incidentes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------+\n",
      "|casosAcumulado|casosNovos|Incidentes|\n",
      "+--------------+----------+----------+\n",
      "|      18855015|     62504|   8972.29|\n",
      "+--------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "painel2_vf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizão 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "painel3 = painel.join(max_data, painel.data == max_data.max_data, 'inner')\\\n",
    ".filter(painel.regiao == \"Brasil\")\\\n",
    ".withColumn('mortalidade', round((col(\"obitosAcumulado\")  / col(\"populacaoTCU2019\"))*100000.00,2))\\\n",
    ".withColumn('letalidade', round((col(\"obitosAcumulado\")  / col(\"casosAcumulado\"))*100.00,1))\n",
    "\n",
    "painel3_vf = painel3.select(\"obitosAcumulado\", \"obitosNovos\", \"mortalidade\", \"letalidade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+-----------+----------+\n",
      "|obitosAcumulado|obitosNovos|mortalidade|letalidade|\n",
      "+---------------+-----------+-----------+----------+\n",
      "|         526892|       1780|     250.73|       2.8|\n",
      "+---------------+-----------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "painel3_vf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Salvar a primeira visualização como tabela Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "painel1.write.parquet(\"/user/carlos/covid_painel1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Salvar a segunda visualização com formato parquet e compressão snappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------+\n",
      "|casosAcumulado|casosNovos|Incidentes|\n",
      "+--------------+----------+----------+\n",
      "|      18855015|     62504|   8972.29|\n",
      "+--------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "painel2_vf.write.parquet(\"/user/carlos/covid_painel2\", compression='snappy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Salvar a terceira visualização em um tópico no Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kafka-topics.sh --bootstrap-server localhost:9092 --topic 'painel3-covid-output' --create --partitions 2 --replication-factor 1\n",
    "# kafka-console-producer.sh --broker-list kafka:9092 --topic 'painel3-covid-output'\n",
    "# kafka-console-consumer.sh --bootstrap-server kafka:9092 --topic 'painel3-covid-output'\n",
    "\n",
    "\n",
    "painel3_vf.write.mode(\"overwrite\").json(\"/user/carlos/painel3_covid_c\")\n",
    "\n",
    "socketDF = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\")\\\n",
    "    .option(\"subscribe\", \"painel3-covid-kafka\")\\\n",
    "    .load()\n",
    "\n",
    "\n",
    "userSchema = StructType().add(\"obitosNovos\", \"long\")\\\n",
    "                         .add(\"obitosAcumulado\", \"long\")\\\n",
    "                         .add(\"mortalidade\", \"double\")\\\n",
    "                         .add(\"letalidade\", \"double\")\n",
    "painel3_rds = spark \\\n",
    "    .readStream \\\n",
    "    .schema(userSchema) \\\n",
    "    .json(\"/user/carlos/painel3_covid_c\")  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "painel3_kafka  = painel3_rds.writeStream\\\n",
    ".format(\"kafka\")\\\n",
    ".option(\"kafka.bootstrap.servers\", \"kafka:9092\")\\\n",
    ".option(\"topic\", \"painel3-covid-kafka\")\\\n",
    ".option(\"checkpointLocation\", \"/user/carlos/painel3_covid_kafka\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "drwxr-xr-x   - root supergroup          0 2021-07-11 20:45 /user/carlos/painel3_covid_kafka/commits\r\n",
      "-rw-r--r--   3 root supergroup         45 2021-07-11 20:45 /user/carlos/painel3_covid_kafka/metadata\r\n",
      "drwxr-xr-x   - root supergroup          0 2021-07-11 20:45 /user/carlos/painel3_covid_kafka/offsets\r\n",
      "drwxr-xr-x   - root supergroup          0 2021-07-11 20:45 /user/carlos/painel3_covid_kafka/sources\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/carlos/painel3_covid_kafka"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Criar a visualização pelo Spark com os dados enviados para o HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------+----------+-----------+--------------------+\n",
      "|      regiao|   Casos|Obitos|Incidencia|mortalidade|     Dta_atualizacao|\n",
      "+------------+--------+------+----------+-----------+--------------------+\n",
      "|      Brasil|18855015|526892|   8972.29|     250.73|2021-07-12 00:40:...|\n",
      "|Centro-Oeste| 3833238| 98414|  11760.51|     301.94|2021-07-12 00:40:...|\n",
      "|    Nordeste| 8911474|215648|   7807.27|     188.93|2021-07-12 00:40:...|\n",
      "|       Norte| 3465630| 87690|   9401.64|     237.89|2021-07-12 00:40:...|\n",
      "|     Sudeste|14277606|490622|   8078.18|     277.59|2021-07-12 00:40:...|\n",
      "|         Sul| 7222082|161410|  12046.45|     269.23|2021-07-12 00:40:...|\n",
      "+------------+--------+------+----------+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "painel_regioes = arquivos.join(max_data, arquivos.data == max_data.max_data, 'inner')\\\n",
    ".groupBy(\"regiao\").agg(sum(\"casosAcumulado\").alias(\"Casos\"),\\\n",
    "                       sum(\"obitosAcumulado\").alias(\"Obitos\"),\\\n",
    "                       round((sum(\"casosAcumulado\")  / sum(\"populacaoTCU2019\"))*100000.00,2).alias(\"Incidencia\"),\\\n",
    "                       round((sum(\"obitosAcumulado\")  / sum(\"populacaoTCU2019\"))*100000.00,2).alias(\"mortalidade\"))\\\n",
    ".withColumn(\"Dta_atualizacao\",current_timestamp())\n",
    "\n",
    "\n",
    "\n",
    "painel_regioes.orderBy(\"regiao\").show()\n",
    "\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Salvar a visualização do exercício 6 em um tópico no Elastic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
